{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malware_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "cysecml",
      "language": "python",
      "name": "cysecml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UW8qxQIIGzuU"
      },
      "source": [
        "Machine Learning Approach for Malware Classification\n",
        "## Team\n",
        "  * **Members**:  Nivas V M,Aditya Y,Dinesh Kumar S,Giriraj M\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IN4BYnOpGzuZ",
        "colab": {}
      },
      "source": [
        "import time \n",
        " \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import json \n",
        "import time \n",
        "import pickle \n",
        "import sys \n",
        "import csv \n",
        "import os \n",
        "import os.path as osp \n",
        "import shutil \n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML\n",
        " \n",
        "%matplotlib inline \n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
        "plt.rcParams['image.interpolation'] = 'nearest' \n",
        "plt.rcParams['image.cmap'] = 'gray' \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "# for auto-reloading external modules \n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a_SG9g6bGzuk",
        "colab": {},
        "outputId": "fa67fca7-e654-4f9d-df16-204e64171834"
      },
      "source": [
        "from collections import Counter          # an even easier way to count\n",
        "from multiprocessing import Pool     # for multiprocessing\n",
        "from tqdm import tqdm                    # fancy progress bars\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from nltk import ngrams\n",
        "import pandas\n",
        "import gc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Co4V3AgzGzuv",
        "colab": {}
      },
      "source": [
        "compute_mode = 'gpu'\n",
        "\n",
        "if compute_mode == 'cpu':\n",
        "    device = torch.device('cpu')\n",
        "elif compute_mode == 'gpu':\n",
        "    # If you are using pytorch on the GPU cluster, you have to manually specify which GPU device to use\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'    # Set device ID here\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    raise ValueError('Unrecognized compute mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ls8q2vmqGzu1"
      },
      "source": [
        "# Setup\n",
        "\n",
        "  * Datasets: [train](https://nextcloud.mpi-klsb.mpg.de/index.php/s/pJrRGzm2So2PMZm) (128M) and [test](https://nextcloud.mpi-klsb.mpg.de/index.php/s/zN3yeWzQB3i5WqE) (92M)\n",
        "  * Unpacked under `./data/train` and `./data/test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1aV0_g7KGzu_"
      },
      "source": [
        "Each file encodes the behavior report of a program (potentially a malware) using an encoding scheme called \"The Malware Instruction Set\" (MIST for short).\n",
        "\n",
        "Each file is named as `filename.<malwarename>`:\n",
        "```\n",
        "» ls data/train | head\n",
        "00005ecc06ae3e489042e979717bb1455f17ac9d.NothingFound\n",
        "0008e3d188483aeae0de62d8d3a1479bd63ed8c9.Basun\n",
        "000d2eea77ee037b7ef99586eb2f1433991baca9.Patched\n",
        "000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
        "0010f78d3ffee61101068a0722e09a98959a5f2c.Basun\n",
        "0013cd0a8febd88bfc4333e20486bd1a9816fcbf.Basun\n",
        "0014aca72eb88a7f20fce5a4e000c1f7fff4958a.Texel\n",
        "001ffc75f24a0ae63a7033a01b8152ba371f6154.Texel\n",
        "0022d6ba67d556b931e3ab26abcd7490393703c4.Basun\n",
        "0028c307a125cf0fdc97d7a1ffce118c6e560a70.Swizzor\n",
        "...\n",
        "```\n",
        "and within each file is a sequence of individual systems calls monitored duing the run-time of the binary - e.g. a malware named 'Basun':\n",
        "```\n",
        "» head data/train/000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
        "# process 000006c8 0000066a 022c82f4 00000000 thread 0001 #\n",
        "02 01 | 000006c8 0000066a 00015000\n",
        "02 02 | 00006b2c 047c8042 000b9000\n",
        "02 02 | 00006b2c 047c8042 00108000\n",
        "02 02 | 00006b2c 047c8042 00153000\n",
        "02 02 | 00006b2c 047c8042 00091000\n",
        "02 02 | 00006b2c 047c8042 00049000\n",
        "02 02 | 00006b2c 047c8042 000aa000\n",
        "02 02 | 00006b2c 047c8042 00092000\n",
        "02 02 | 00006b2c 047c8042 00011000\n",
        "...\n",
        "```\n",
        "There are 10 classes: `{ Agent, Allaple, AutoIt, Basun, NothingFound, Patched, Swizzor, Texel, VB, Virut }`, where `NothingFound` roughly represents no malware is present.\n",
        "Our malware detector $F: X \\rightarrow Y$ learns a mapping from the MIST-encoded behaviour report (the input $x \\in X$) to the malware class $y \\in Y$.\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hAAX1evdGzvB"
      },
      "source": [
        "# 1. Vectorize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ejfxh7cIGzvC"
      },
      "source": [
        "## 1.a. Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GV-lhGtNGzvE",
        "colab": {}
      },
      "source": [
        "def file_load_kernel(filepath):\n",
        "    '''Given a filepath, returns (content, classname), where content = [list of lines in file]'''\n",
        "    lines = open(filepath, 'r').readlines()\n",
        "    label = filepath.split('.')[-1]\n",
        "    return lines, label\n",
        "\n",
        "def load_data(data_path, nworkers=10):\n",
        "    '''Returns each data sample as a tuple (x, y), x = sequence of strings (i.e., syscalls), y = malware program class'''\n",
        "    raw_data_samples = []\n",
        "    absolute_data_path = os.path.join(os.getcwd(), data_path)\n",
        "    data_path_files = os.listdir(absolute_data_path)\n",
        "    with tqdm(total=len(data_path_files)) as pbar:\n",
        "        for file in data_path_files:\n",
        "            content, label = file_load_kernel(os.path.join(absolute_data_path, file))\n",
        "            raw_data_samples.append((content, label))\n",
        "            pbar.update(1)\n",
        "    return raw_data_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dkip9oZiGzvI",
        "scrolled": true,
        "colab": {},
        "outputId": "97376f9f-8dc7-42a2-b979-e067bcebbdf2"
      },
      "source": [
        "print('=> Loading training data ... ')\n",
        "train_raw_samples = load_data(Path('./data/train'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading training data ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 13682/13682 [01:41<00:00, 135.33it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KP6YS2dhGzvP",
        "colab": {},
        "outputId": "79a0bfeb-2d48-4a35-f813-1bec47857762"
      },
      "source": [
        "project_mode = 'traintest'    # trainval, traintest, debug\n",
        "np.random.seed(123)          # To perform the same split across multiple runs\n",
        "\n",
        "if project_mode == 'trainval':\n",
        "    # Train = train subset; Test (i.e., validation) = train subset\n",
        "    val_frac = 0.25\n",
        "    np.random.shuffle(train_raw_samples)\n",
        "    split_idx = int(len(train_raw_samples) * val_frac)\n",
        "    test_raw_samples, train_raw_samples = train_raw_samples[:split_idx], train_raw_samples[split_idx:]\n",
        "elif project_mode == 'traintest':\n",
        "    # Train = full train set; Test = full test set\n",
        "    test_raw_samples = load_data(Path('./data/test'))\n",
        "elif project_mode == 'debug':\n",
        "    # Train = train micro-subset; Test (i.e., validation) = train micro-subset\n",
        "    np.random.shuffle(train_raw_samples)\n",
        "    train_raw_samples, test_raw_samples = train_raw_samples[:1000], train_raw_samples[1000:2000]\n",
        "else:\n",
        "    raise ValueError('Unrecognized mode')\n",
        "    \n",
        "print('=> # Train samples = ', len(train_raw_samples))\n",
        "print('=> # Test  samples = ', len(test_raw_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:16<00:00, 130.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=> # Train samples =  13682\n",
            "=> # Test  samples =  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3mnKnk99GzvT"
      },
      "source": [
        "## 1.b. Vectorize: Setup\n",
        "\n",
        "Idenfitcation of relevant features/tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JiRzORZIGzvV",
        "colab": {}
      },
      "source": [
        "class_to_idx = {'Agent':0, 'Allaple':1, 'AutoIt':2, 'Basun':3, 'NothingFound':4, 'Patched':5, 'Swizzor':6, 'Texel':7, 'VB':8, 'Virut':9}\n",
        "\n",
        "def get_key_idx_map(counter, vocab_size, ukn_token='_ukn_'):\n",
        "    # counter is a mapping: token -> count\n",
        "    # build vectorizer using vocab_size most common elements\n",
        "    key_to_idx, idx_to_key = dict(), dict()\n",
        "    count_data = list(counter.most_common(vocab_size))\n",
        "    \n",
        "    incrementor = 0\n",
        "    \n",
        "    with tqdm(total=len(count_data)) as pbar:\n",
        "        for word, count in count_data:\n",
        "            key_to_idx[word] = incrementor\n",
        "            idx_to_key[incrementor] = word\n",
        "            incrementor += 1\n",
        "            pbar.update(1)\n",
        "    return key_to_idx, idx_to_key\n",
        "\n",
        "def helper1_tokenize(train_raw_samples):\n",
        "    tokenized_data = []\n",
        "    with tqdm(total=len(train_raw_samples)) as pbar:\n",
        "        for content, label in train_raw_samples:\n",
        "            tokens = []\n",
        "            for line in content[1: -1]:\n",
        "                tokens.extend(text_to_word_sequence(line))\n",
        "            tokenized_data.append(tokens)\n",
        "            pbar.update(1)\n",
        "    return tokenized_data\n",
        "    pass\n",
        "\n",
        "def helper2_ngrams(tokens, n=2):\n",
        "    n_grams = []\n",
        "    with tqdm(total=len(tokens)) as pbar:\n",
        "        for token_set in tokens:\n",
        "            n_grams.append(list(ngrams(token_set, n)))\n",
        "            pbar.update(1)\n",
        "    return n_grams\n",
        "    pass\n",
        "\n",
        "def helper3_get_class_to_idx_map(raw_samples):\n",
        "    labels_y = list()\n",
        "    with tqdm(total=len(raw_samples)) as pbar:\n",
        "        for counter, labels in raw_samples:\n",
        "            labels_y.append(class_to_idx[labels])\n",
        "            pbar.update(1)\n",
        "    return np.array(labels_y)\n",
        "\n",
        "def plot_scores(x, y, title = \"Title\", x_label = \"X\", y_label = \"Y\"):\n",
        "    fig, ax = plt.subplots(nrows=1,ncols=1)\n",
        "\n",
        "    ax.plot(x, y)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(x_label)\n",
        "    ax.set_ylabel(y_label)\n",
        "    ax.set_ylim(0.1, 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TDTNsdrRGzvZ",
        "colab": {},
        "outputId": "01d8857d-766b-4c77-f6ee-387e6961f8b5"
      },
      "source": [
        "np.random.shuffle(train_raw_samples)\n",
        "np.random.shuffle(test_raw_samples)\n",
        "\n",
        "train_raw_samples, test_raw_samples = train_raw_samples[:1500], test_raw_samples[:1500]\n",
        "\n",
        "print('=> # Train samples = ', len(train_raw_samples))\n",
        "print('=> # Test  samples = ', len(test_raw_samples))\n",
        "\n",
        "tokens = helper1_tokenize(train_raw_samples)\n",
        "\n",
        "#unigrams = helper2_ngrams(tokens, 1)\n",
        "bigrams = helper2_ngrams(tokens, 2)\n",
        "#trigrams = helper2_ngrams(tokens, 3)\n",
        "\n",
        "tokens = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> # Train samples =  1500\n",
            "=> # Test  samples =  1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:40<00:00,  9.33it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:51<00:00, 29.14it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcT5HpZOGzvg",
        "colab": {},
        "outputId": "13d1a8d2-8eb9-487c-c46d-d9c50bcd367e"
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "MAX_VOCAB_SIZE = 700\n",
        "\n",
        "ngram_tokens = []\n",
        "for ngram_set in bigrams:\n",
        "    ngram_tokens.extend(ngram_set)\n",
        "\n",
        "token_to_idx, idx_to_token = get_key_idx_map(Counter(ngram_tokens), MAX_VOCAB_SIZE)\n",
        "ngram_tokens = []\n",
        "train_y = helper3_get_class_to_idx_map(train_raw_samples)\n",
        "test_y = helper3_get_class_to_idx_map(test_raw_samples)\n",
        "\n",
        "# Save vocab to file\n",
        "    \n",
        "out_path = 'application_vocab_{}.pkl'.format(MAX_VOCAB_SIZE)\n",
        "with open(out_path, 'wb') as wf:\n",
        "    dct = {'token_to_idx': token_to_idx,\n",
        "          'idx_to_token': idx_to_token}\n",
        "    pickle.dump(dct, wf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 100259.96it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 7335.79it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 12394.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v8hgmFHiGzvj"
      },
      "source": [
        "## 1.c. Vectorize Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XzkZjecJGzvl",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "def Binary_Vectorizer(tokens):\n",
        "    vectorized_samples = []\n",
        "    with tqdm(total=len(tokens)) as pbar:\n",
        "        for token_set in tokens:\n",
        "            vectorized_sample = np.zeros(MAX_VOCAB_SIZE)\n",
        "            for word in token_set:\n",
        "                if word in token_to_idx:\n",
        "                    vectorized_sample[token_to_idx[word]] = 1\n",
        "            vectorized_samples.append(np.array(vectorized_sample, dtype='float32'))\n",
        "            pbar.update(1)\n",
        "    return np.array(vectorized_samples, dtype='float32')\n",
        "\n",
        "def Count_Vectorizer(ngram_data):\n",
        "    vectorized_samples = []\n",
        "    with tqdm(total=len(ngram_data)) as pbar:\n",
        "        for ngram_set in ngram_data:\n",
        "            vectorized_sample = np.zeros(MAX_VOCAB_SIZE)\n",
        "            token_counter = dict(Counter(ngram_set))\n",
        "            unique_tokens = list(token_counter.keys())\n",
        "            for token in unique_tokens:\n",
        "                if token in token_to_idx:\n",
        "                    vectorized_sample[token_to_idx[token]] = token_counter[token]\n",
        "            vectorized_samples.append(np.array(vectorized_sample, dtype='float32'))\n",
        "            pbar.update(1)\n",
        "    return np.array(vectorized_samples, dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SUSZer4yGzvo",
        "colab": {}
      },
      "source": [
        "def vectorize_raw_samples(raw_samples, nworkers=10):\n",
        "    vectorized_samples = []\n",
        "    tokens = helper1_tokenize(raw_samples)\n",
        "    ngram_data = helper2_ngrams(tokens, 2)\n",
        "    vectorized_samples = Binary_Vectorizer(ngram_data)\n",
        "    return vectorized_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SfMBSG6NGzvt",
        "scrolled": true,
        "colab": {},
        "outputId": "97a3e2b5-a094-4efe-c066-6860a76527a1"
      },
      "source": [
        "print('=> Processing: Train')\n",
        "train_data = vectorize_raw_samples(train_raw_samples)\n",
        "print()\n",
        "print('=> Processing: Test')\n",
        "test_data = vectorize_raw_samples(test_raw_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Processing: Train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [03:01<00:00,  8.25it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [01:02<00:00, 24.11it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [01:10<00:00, 21.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=> Processing: Test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:40<00:00,  9.34it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:50<00:00, 29.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [01:04<00:00, 23.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0l9dsxjxGzwA",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "gaussianNB = GaussianNB()\n",
        "\n",
        "gaussianNB.fit(train_data, train_y)\n",
        "y_pred = gaussianNB.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JJT87gLLGzwF",
        "colab": {},
        "outputId": "7bfa2803-9509-47a1-f121-93c924f025f8"
      },
      "source": [
        "print(\"Accuracy: \",metrics.accuracy_score(test_y, y_pred))\n",
        "print(\"Precision: \",metrics.precision_score(test_y, y_pred, average='weighted'))\n",
        "print(\"Recall: \",metrics.recall_score(test_y, y_pred, average='weighted'))\n",
        "print(\"F1 Score: \", metrics.f1_score(test_y, y_pred, average='weighted'))\n",
        "print(\"Confusion Matrix: \", metrics.confusion_matrix(test_y, y_pred))\n",
        "print(\"Classification Report: \", metrics.classification_report(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.47333333333333333\n",
            "Precision:  0.6434914002206916\n",
            "Recall:  0.47333333333333333\n",
            "F1 Score:  0.4245263758876105\n",
            "Confusion Matrix:  [[ 25   0   0   0  11   0   0   2   3  10]\n",
            " [  0  54   0   0   0   0   0   0   0   0]\n",
            " [  0   0  76   0   0   0   0   0   0   0]\n",
            " [  0   0   0 212   1   0   0   0   0   0]\n",
            " [ 96   1   1  75  40  44   0   6  46  88]\n",
            " [  4   0   0   0   1  31   0   9   2   5]\n",
            " [  0   0   0   0   0   0  60   0   0   0]\n",
            " [ 18   0   0   0   1 225   1  40   9 106]\n",
            " [  0   0   0   0   5   1   0   0  61   8]\n",
            " [  1   0   0   0   4   4   0   1   1 111]]\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.49      0.26        51\n",
            "           1       0.98      1.00      0.99        54\n",
            "           2       0.99      1.00      0.99        76\n",
            "           3       0.74      1.00      0.85       213\n",
            "           4       0.63      0.10      0.17       397\n",
            "           5       0.10      0.60      0.17        52\n",
            "           6       0.98      1.00      0.99        60\n",
            "           7       0.69      0.10      0.17       400\n",
            "           8       0.50      0.81      0.62        75\n",
            "           9       0.34      0.91      0.49       122\n",
            "\n",
            "    accuracy                           0.47      1500\n",
            "   macro avg       0.61      0.70      0.57      1500\n",
            "weighted avg       0.64      0.47      0.42      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9j7WvXYGzvy",
        "colab": {},
        "outputId": "e1f72176-9e58-400b-f8f8-18fc10635695"
      },
      "source": [
        "# test for different values of k\n",
        "kVals = range(1, 21)\n",
        "accuracies = []\n",
        "\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "    knn.fit(train_data, train_y)\n",
        " \n",
        "    score = knn.score(test_data, test_y)\n",
        "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
        "    accuracies.append(score)\n",
        "\n",
        "i = int(np.argmax(accuracies))\n",
        "knn = KNeighborsClassifier(n_neighbors=kVals[i], weights='distance')\n",
        "knn.fit(train_data, train_y)\n",
        "y_pred = knn.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k=1, accuracy=77.13%\n",
            "k=2, accuracy=77.40%\n",
            "k=3, accuracy=79.27%\n",
            "k=4, accuracy=79.73%\n",
            "k=5, accuracy=79.73%\n",
            "k=6, accuracy=79.20%\n",
            "k=7, accuracy=79.40%\n",
            "k=8, accuracy=79.67%\n",
            "k=9, accuracy=79.60%\n",
            "k=10, accuracy=79.80%\n",
            "k=11, accuracy=79.13%\n",
            "k=12, accuracy=79.73%\n",
            "k=13, accuracy=79.13%\n",
            "k=14, accuracy=79.40%\n",
            "k=15, accuracy=79.40%\n",
            "k=16, accuracy=79.00%\n",
            "k=17, accuracy=79.20%\n",
            "k=18, accuracy=79.07%\n",
            "k=19, accuracy=79.07%\n",
            "k=20, accuracy=79.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CfFYe51ZGzv7",
        "colab": {},
        "outputId": "f2162472-5788-4801-fdf0-e0d9db65e534"
      },
      "source": [
        "print(\"Accuracy: \",metrics.accuracy_score(test_y, y_pred))\n",
        "print(\"Precision: \",metrics.precision_score(test_y, y_pred, average='weighted'))\n",
        "print(\"Recall: \",metrics.recall_score(test_y, y_pred, average='weighted'))\n",
        "print(\"F1 Score: \", metrics.f1_score(test_y, y_pred, average='weighted'))\n",
        "print(\"Confusion Matrix: \", metrics.confusion_matrix(test_y, y_pred))\n",
        "print(\"Classification Report: \", metrics.classification_report(test_y, y_pred))\n",
        "plot_scores(kVals, accuracies, title=\"kNN Comparative Scores\", x_label='#Neighbors (k)', y_label='Accuracy')\n",
        "\n",
        "kVals = []\n",
        "accuracies = []\n",
        "kNN = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.798\n",
            "Precision:  0.7849174199718443\n",
            "Recall:  0.798\n",
            "F1 Score:  0.7769292908768971\n",
            "Confusion Matrix:  [[ 12   0   0   0  19   0   7  12   0   1]\n",
            " [  0  54   0   0   0   0   0   0   0   0]\n",
            " [  0   0  76   0   0   0   0   0   0   0]\n",
            " [  0   0   0 208   5   0   0   0   0   0]\n",
            " [  6   1   1  61 253   0   6  64   0   5]\n",
            " [  0   0   0   0   2   1   0  49   0   0]\n",
            " [  0   0   0   0   0   0  60   0   0   0]\n",
            " [  0   0   0   0  19   4   2 370   0   5]\n",
            " [  0   0   0   0  13   0   2   1  59   0]\n",
            " [  0   0   0   0   6   0   1  11   0 104]]\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.24      0.35        51\n",
            "           1       0.98      1.00      0.99        54\n",
            "           2       0.99      1.00      0.99        76\n",
            "           3       0.77      0.98      0.86       213\n",
            "           4       0.80      0.64      0.71       397\n",
            "           5       0.20      0.02      0.04        52\n",
            "           6       0.77      1.00      0.87        60\n",
            "           7       0.73      0.93      0.82       400\n",
            "           8       1.00      0.79      0.88        75\n",
            "           9       0.90      0.85      0.88       122\n",
            "\n",
            "    accuracy                           0.80      1500\n",
            "   macro avg       0.78      0.74      0.74      1500\n",
            "weighted avg       0.78      0.80      0.78      1500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZwdVZ338c+396wESCdCFkAMYEQFbQPqCCiIBJ3EbRR0RnHL6GNAUVQYGFTcUUef5zW4oCKjiIgoGjEKuADjAiTsCQGNEUgIkoYQsvf6e/441eHm5nb3vZ2uDkl936/Xfd1azjl17r1161d1quqUIgIzMyuuul1dATMz27UcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcAGJekBSSfs6nrsqST9h6Rv7+p6WHE5ENhOyYLEo5LGlEx7t6QbSsZD0j2S6kqmfVrSpQOUO17SVyU9JGmjpOXZ+MS8PstIkHScpFWl0yLisxHx7hyW9RxJ10l6QtI6SbdJOnm4l2O7PwcCGw4NwAcGSbM/cEo1hUlqAn4LPAc4CRgPvAR4HJg19GrmS8nT6T/1C+B6YDIwCTgDWD+cC5DUMJzl2a7xdFppbTcg6TBJf5dUulH/InCWpAkDZL0Q+GSVG463AdOB10XEvRHRGxFrIuJTEbEwq8ezJd2Q7ekulTSnpI6XSvqapF9lRxN/lPSM7IjiCUn3STqyJP0Dks6RdG82/7uSWrJ5e0u6RlJ7Nu8aSVNL8t4g6TOS/ghsBp4p6R2SlknaIGmFpH/P0o4BfgXsn9Vro6T9JX1C0mVZml9Lml/2nd8l6fUl3//1ktZKul/Smyp9gdmR00HAtyKiM3v9MSL+UJJmrqQ7Ja2X9DdJJ2XT95e0IFvGcknvKcnzCUlXSbpM0nrgNEl1ks7Oynhc0pWS9snSt2RpH89+q0WSJlexDtgIciCwqkl6AXAdcHpEXFEyazFwA3DWANl/StobPa2KRZ0A/DoiNvZTj0bS3u51pD3d04EfSDq0JNmbgPOAiUAH8Gfg9mz8KuC/yop9K/Aq4GDgkCwvpP/Id4EDSMFpC/DfZXn/DZgHjAMeBNYAryEdybwD+IqkF0TEJmA2sDoixmav1WVlXQ6cWvJZZ2bL/mUWSK7P0kzK0n1N0nMqfE2PA8uByyS9tnzjK2kW8D3gI8AE4BjggWz2D4FVpKO4NwKflXR8Sfa5pO9wAvAD0pHGa4FjszxPABdlad8O7AVMA/YF3pt9h/Y04kBg1XoZsAB4e0RcU2H++cDpklr7yR/AfwLnS2oeZFn7Ao8MMP9oYCzw+WxP93fANZRsQIGrI+K2iNgKXA1sjYjvRUQP8CPgyLIy/zsiVkbEWuAzfWVFxOMR8ZOI2BwRG7J5x5blvTQilkZEd0R0RcQvI+JvkdxIClgvG+Qzb6s3cISkA7LxtwI/jYgOUnB5ICK+my3rduAnpI31diJ1IvZy0sb9y8Ajkm6SNCNL8i7gkoi4Pjviejgi7pM0Dfgn4GMRsTUi7gS+TQp2ff4cET/L8m0B/h04NyJWZfX8BPDG7Oivi/R7PisierLfZFibp2znORBYtd4L/Ckifl9pZkQsIW2Mz+6vgKxZ5yHS3vNAHgf2G2D+/sDKiOgtmfYgMKVk/NGS4S0VxseWlbmyrKz9ASSNlvRNSQ9mTSE3ARMk1feTF0mzJd2cNa2sA04mHYkMKgs2v+Sp8ymnkPa6IR0ZHJU1sazLyn4r8Ix+yloVEfMj4uAs7ybSUQCkPfS/Vci2P7A2q0ef8u925fZZOAC4uqROy4Ae0rmJ7wPXAldIWi3pwuyIzp5GHAisWu8Fpkv6ygBpPg68h+03GuXOA84FRg+Q5jfAq1RyJVKZ1cC0shOz04GHByhzMNPKyuprsvkwcChwVESMJzWhAKgk/bYufLOjnZ8AXwImR8QEYGFJ+mq6+/0hcKqkFwOjgL7guxK4MSImlLzGRsT7BiswIlaSmmsOLynr4ApJVwP7SBpXMq38uy3/DCuB2WX1asmOMroi4pMRMZN0wv81pHNA9jTiQGDV2kC6gucYSZ+vlCAilpOaXc7or5CIuAG4h9R23J/vkzYuP8lOjtZJ2lfpevuTgVtIe7cfldQo6Tjgn4Er+i9yUO+XNDU7yfkf2eeA1O6/BViXzfv4IOU0Ac1AO9AtaTZwYsn8R4F9Je01QBkLSXvZFwA/KjnyuQY4RNK/ZZ+7UdKLJD27vIDsJPcnJT0r+/4mAu8Ebs6SfAd4h6Tjs/lTJB2WBYw/AZ/LTvQ+j9SM9IPyZZT4BvCZvuYsSa2S5mbDL5f03OwIaj2pqahngLJsF3AgsKpFxDrglcBsSZ/qJ9kFQH978n3OA/YZYDkdpBPG95FOjq4HbiU1r9wSEZ3AHNKJ18eArwFvi4j7qv80O7ic1Ja/Int9Opv+VdJe+WOkjeivByoka1I5A7iSdNL0LaRzK33z7yPt8a/ImlL2r1BGB+nk+glZvUrLPpHUXLQa+AfwBVLgKdcJHEg6uloPLCGdND8tK+tWshPZwJPAjaTgA+n8yIHZMq4GPh4R1w/wsf9v9hmvk7SB9D0dlc17BunE8npSk9GNwGUDlGW7gPxgGis6SQ8A746I3+zqupjtCj4iMDMruNwCgaRLJK2RtKSf+ZL0/7IbVu7OrlE3M7MRlucRwaWkk4v9mQ3MyF7zgK/nWBezfkXEgW4WsiLLLRBExE3A2gGSzAW+l910czPp2uyBrh03M7Mc7MoOo6aw/Y0pq7JpO9xRKmke2U1IY8aMeeFhhx02IhU0M9tT3HbbbY9FRMU7/3dlIFCFaRUvYYqIi4GLAdra2mLx4sV51svMbI8j6cH+5u3Kq4ZWsf3dnFN56m5OMzMbIbsyECwA3pZdPXQ08GREDNTRmJmZ5SC3piFJPwSOAyYqPZHp40AjQER8g3Qb/cmkrnI3k+5yNDOzEZZbIIiIUweZH8D781q+mZlVx3cWm5kVnAOBmVnBORCYmRWcA4GZWcE5EJiZFZwDgZlZwTkQmJkVnAOBmVnBORCYmRWcA4GZWcE5EJiZFZwDgZlZwTkQmJkVnAOBmVnBORCYmRVcroFA0kmS7pe0XNLZFeYfIOm3ku6WdIOkqXnWx8zMdpRbIJBUD1wEzAZmAqdKmlmW7EvA9yLiecAFwOfyqo+ZmVWW5xHBLGB5RKyIiE7gCmBuWZqZwG+z4d9XmG9mZjnLMxBMAVaWjK/KppW6C3hDNvw6YJykfXOsk5mZlckzEKjCtCgbPws4VtIdwLHAw0D3DgVJ8yQtlrS4vb19+GtqZlZgeQaCVcC0kvGpwOrSBBGxOiJeHxFHAudm054sLygiLo6Itohoa21tzbHKZmbFk2cgWATMkHSQpCbgFGBBaQJJEyX11eEc4JIc62NmZhXkFggiohuYD1wLLAOujIilki6QNCdLdhxwv6S/AJOBz+RVHzMzq0wR5c32T29tbW2xePHiXV0NM7PdiqTbIqKt0jzfWWxmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYFl2sgkHSSpPslLZd0doX50yX9XtIdku6WdHKe9TEzsx3lFggk1QMXAbOBmcCpkmaWJTuP9AjLI0nPNP5aXvUxM7PKGnIsexawPCJWAEi6ApgL3FuSJoDx2fBewOoc67Pb6Ozu5cktXTy5pZN1m7vSa0sXG7d27VS59XViwugm9h3TxN5j0vuE0U00NTx9Wggjgo7uXrZ29bClq4fNnT1s6exha1cPHd29CKirE3US9XUgiXql8bo6sunZuHhquE6I9N12dPdm7z07DG97dfXQ2dNLR9dT6Xt6e9l3bDOTxzczaXwLk8Y1M3l8C/uMbqKuTsP+PTy5pYvHNnbQvqGTxzZ28OSWLvYa1cjEsc20jmti4thm9hrViDS8y7biyTMQTAFWloyvAo4qS/MJ4DpJpwNjgBMqFSRpHjAPYPr06cNe0ZGwZv1W7li5jnWbO7dt2Ndt3n5j/+SWLtZt7mRTZ8+I1m1cS8N2wWHv0U3sM/ap4X3HNrHPmGbGtTTQ3RM7bkC7dty4PvV6an5Hd9qgb+lMG/jSjX3f9C1dPfQ+zR6j3VRfR3NDHRKs39q9w/yGOtE6LgWHyeOamTS+mcnjWpg8voVJ45uZNK6FyeObmTC6ifVbumjf2MFjGzrS+8a0kX9sQ0d639hJ+4YOHt/UQVfP4F9EY73Yd0wzreOamTg2BYeJ45rT+9gmWsc10zo2jU8Y3Uh3b7Clq4et2W+wJfsNysf7fovS961dPezMTyNgTHMD41saGNfSyPhR2XtLI+NaGhjX0sD4UWm4uaF+J5aUdPc8tR52Zq+6Omisr6OhTjTU19FYLxrq0nuRA2qegaDSt1q+Hp0KXBoRX5b0YuD7kg6PiN7tMkVcDFwM6eH1udR2mHV293Lbg09w41/aufEv7Sx7ZP128xvqxITRjew1qpEJo5vYb68WDttvHBNGNbH36MY0b3QTE0al4QmjmhjTXE/dTqysXb29rNvcxdpNnf2+Vq/bypKH17N2UyedPb2DFzqI5oY6mhrqaG6op7mhjlFN9YxuqqelsZ4Jo5vYv6meUY31tDTVM7qxnlHZvFGNKV3f+Oimeprq6wigN4Le3vTeE0Fvb9Ab0NMbaV4EPb1BZNN6IohIaZrq62hufKo+29WvsW6H+jbV1223t9/R3UP7hg4eXd9B+4atPLq+g0fXb2XNhvT+4OObufWBtazbXP3RW0Odsg142pAf+oxxO27Ix6W9/ye3dG0XRNq3BZA0bdkjG3hsYwfdFaKpBDGEf09LY136jRp3bv3rjWBjRzcbO7oHrUdzQ11ZsGhgbHMD3b1R4WgujW8b7krjte5QpOAgGuvqaKjPAkUWMPqm72ys2G7dzNbVbevytvW3ZF3uW7ezdfiTcw7nLUcN/85wnoFgFTCtZHwqOzb9vAs4CSAi/iypBZgIrMmxXrlZuXbztg3/n5Y/xqbOHhrqRNuBe/Oxkw7j6GfuQ+u4tGc4pql+l+yBTBrXUlW6iGBTZw9rN3aydnMnazd1sH5Ld7aR3H5j2dxYl21g60vmpWl72l5Wc0M9U/cezdS9Rw+YbmtXChhrsmCxZv1W1m7uYsKoxmyPvYnWsWlPvpbmncnjWzhk8rgB05Q2K63ZkB11bOhg3eZOGutTMB6VBeBRjSXDJUE6BeIGmhvqhr3Zq7c32NjZzYat3WzY2sX6Ldn71i42bO1m/ZbsfWv3dtP+8eRW6uu0bT0b29xA85i0HvatcwOtm431dfT2Bl29vXT3BF09vXT3Bt09vXT1BN296b2rJ83vG+/u6aUrSzeUQFpqW9NlXdZ0qXQkUp81a5ZOf6oJVCib9uz9Bv7thyrPQLAImCHpIOBh0sngt5SleQg4HrhU0rOBFqA9xzoNq61dPdy84vFtG/8V7ZsAmDJhFK89cgrHHtLKS541kbHNeX7N+ZDE2Oa0FzZ934E3erajlsZ6pu0zmmn7jPx3J6VzQRNGN/GsSflsOHZGXZ0YnzUJwahdXR0jx0AQEd2S5gPXAvXAJRGxVNIFwOKIWAB8GPiWpDNJzUanRexszM1PRPC39k3bNvy3rHicju5emhvqOPqZ+/KvRx3AsYe28syJY/a4PWEz23PpabzdraitrS0WL15cc74nt3TRvqGj4tUofSfJ0nA3Wzp7sxNk3dnJs162dvbw8LotPLxuCwAHt47h2EMmceyhrRx10D60NO78yS0zs7xIui0i2irN2/3aLIbo8lse4gu/vm/QdHWC0U0N205Qlp7IfP60vXjfcQdz7CGtu+SQ38wsD4UJBMc/exL7T2jZdhJsVFPddifF0gZ/zzzBaWY2kMIEgkMmjxv0agszsyJ6+txSamZmu4QDgZlZwTkQmJkVnAOBmVnBORCYmRWcA4GZWcE5EJiZFZwDgZlZwTkQmJkVnAOBmVnBORCYmRWcA4GZWcHlGggknSTpfknLJZ1dYf5XJN2Zvf4iaV2e9TEzsx3l1vuopHrgIuCVpOcXL5K0ICLu7UsTEWeWpD8dODKv+piZWWV5HhHMApZHxIqI6ASuAOYOkP5U4Ic51sfMzCrIMxBMAVaWjK/Kpu1A0gHAQcDv+pk/T9JiSYvb23ebZ9ubme0W8gwElR7z1d8Dkk8BroqInkozI+LiiGiLiLbW1tZhq6CZmeUbCFYB00rGpwKr+0l7Cm4WMjPbJfIMBIuAGZIOktRE2tgvKE8k6VBgb+DPOdbFzMz6kVsgiIhuYD5wLbAMuDIilkq6QNKckqSnAldERH/NRmZmlqNcH14fEQuBhWXTzi8b/0SedTAzs4H5zmIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMruEEDgaT5kvYeicqYmdnIq+aI4Bmkx0xemT2DuNJzBszMbDc1aCCIiPOAGcB3gNOAv0r6rKSDc66bmZmNgKrOEWRdRP8je3WTnh9wlaQLc6ybmZmNgEG7oZZ0BvB24DHg28BHIqJLUh3wV+Cj+VbRzMzyVM0RwUTg9RHxqoj4cUR0AUREL/CagTJm5xTul7Rc0tn9pHmTpHslLZV0ec2fwMzMdko1D6ZZCKztG5E0DpgZEbdExLL+MkmqBy4CXkl6fvEiSQsi4t6SNDOAc4CXRsQTkiYN8XOYmdkQVXNE8HVgY8n4pmzaYGYByyNiRUR0AlcAc8vSvAe4KCKeAIiINVWUa2Zmw6iaQKDS5wlnTULVHElMAVaWjK/KppU6BDhE0h8l3SzppIoVkOZJWixpcXt7exWLNjOzalUTCFZIOkNSY/b6ALCiinyV7jcof0B9A+nS1ONID7H/tqQJO2SKuDgi2iKirbW1tYpFm5lZtaoJBO8FXgI8TNqrPwqYV0W+VcC0kvGpwOoKaX4eEV0R8XfgflJgMDOzETJoE0/Wbn/KEMpeBMyQdBApiJwCvKUszc9IRwKXSppIaiqq5mjDzMyGSTX3EbQA7wKeA7T0TY+Idw6ULyK6Jc0HrgXqgUsiYqmkC4DFEbEgm3eipHuBHtI9Co8P+dOYmVnNqjnp+33gPuBVwAXAW4F+LxstFRELSZeflk47v2Q4gA9lLzMz2wWqOUfwrIj4T2BTRPwP8GrguflWy8zMRko1gaAre18n6XBgL+DA3GpkZmYjqpqmoYuz5xGcBywAxgL/mWutzMxsxAwYCLKO5dZnd/7eBDxzRGplZmYjZsCmoewu4vkjVBczM9sFqjlHcL2ksyRNk7RP3yv3mpmZ2Yio5hxB3/0C7y+ZFriZyMxsj1DNncUHjURFzMxs16jmzuK3VZoeEd8b/uqYmdlIq6Zp6EUlwy3A8cDtgAOBmdkeoJqmodNLxyXtRep2wszM9gDVXDVUbjPuKtrMbI9RzTmCX/DUA2XqgJnAlXlWyszMRk415wi+VDLcDTwYEatyqo+ZmY2wagLBQ8AjEbEVQNIoSQdGxAO51szMzEZENecIfgz0loz3ZNMGJekkSfdLWi7p7ArzT5PULunO7PXu6qptZmbDpZojgoaI6OwbiYhOSU2DZZJUD1wEvJL0bOJFkhZExL1lSX8UEe7PyMxsF6nmiKBd0py+EUlzgceqyDcLWB4RK7JAcgUwd2jVNDOzvFQTCN4L/IekhyQ9BHwM+Pcq8k0BVpaMr8qmlXuDpLslXSVpWqWCJM2TtFjS4vb29ioWbWZm1Ro0EETE3yLiaNJlo8+JiJdExPIqylal4srGfwEcGBHPA34D/E8/dbg4Itoioq21tbWKRZuZWbUGDQSSPitpQkRsjIgNkvaW9Okqyl4FlO7hTwVWlyaIiMcjoiMb/RbwwmorbmZmw6OapqHZEbGubyR7WtnJVeRbBMyQdFB2cvkU0qMut5G0X8noHGBZFeWamdkwquaqoXpJzX177pJGAc2DZYqIbknzgWuBeuCSiFgq6QJgcUQsAM7ITkR3A2uB04b4OczMbIiqCQSXAb+V9N1s/B3005ZfLiIWAgvLpp1fMnwOcE51VTUzszxU0/vohZLuBk4gnQD+NXBA3hUzM7ORUW3vo/8g3V38BtLzCNyWb2a2h+j3iEDSIaQTvKcCjwM/AhQRLx+hupmZ2QgYqGnoPuB/gX/uu29A0pkjUiszMxsxAzUNvYHUJPR7Sd+SdDyVbxIzM7PdWL+BICKujog3A4cBNwBnApMlfV3SiSNUPzMzy1k1XUxsiogfRMRrSHcH3wns0KW0mZntnmp6ZnFErI2Ib0bEK/KqkJmZjayhPLzezMz2IA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcLkGAkknSbpf0nJJ/d6EJumNkkJSW571MTOzHeUWCCTVAxcBs0kPvj9V0swK6cYBZwC35FUXMzPrX55HBLOA5RGxIiI6gSuAuRXSfQq4ENiaY13MzKwfeQaCKcDKkvFV2bRtJB0JTIuIawYqSNI8SYslLW5vbx/+mpqZFViegaBSl9WxbaZUB3wF+PBgBUXExRHRFhFtra2tw1hFMzPLMxCsAqaVjE8FVpeMjwMOB26Q9ABwNLDAJ4zNzEZWnoFgETBD0kGSmkiPvVzQNzMinoyIiRFxYEQcCNwMzImIxTnWyczMyuQWCCKiG5gPXEt62P2VEbFU0gWS5uS1XDMzq81AzyzeaRGxEFhYNu38ftIel2ddzMysMt9ZbGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwuQYCSSdJul/ScklnV5j/Xkn3SLpT0h8kzcyzPmZmtqPcAoGkeuAiYDYwEzi1wob+8oh4bkQcAVwI/Fde9TEzs8ryPCKYBSyPiBUR0QlcAcwtTRAR60tGxwCRY33MzKyCPB9VOQVYWTK+CjiqPJGk9wMfApqAV1QqSNI8YB7A9OnTh72iZmZFlucRgSpM22GPPyIuioiDgY8B51UqKCIujoi2iGhrbW0d5mqamRVbnoFgFTCtZHwqsHqA9FcAr82xPmZmVkGegWARMEPSQZKagFOABaUJJM0oGX018Ncc62NmZhXkdo4gIrolzQeuBeqBSyJiqaQLgMURsQCYL+kEoAt4Anh7XvUxM7PK8jxZTEQsBBaWTTu/ZPgDeS7fzMwG5zuLzcwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzAou10Ag6SRJ90taLunsCvM/JOleSXdL+q2kA/Ksj5mZ7Si3QCCpHrgImA3MBE6VNLMs2R1AW0Q8D7gKuDCv+piZWWV5HhHMApZHxIqI6CQ9nH5uaYKI+H1EbM5GbyY94N7MzEZQnoFgCrCyZHxVNq0/7wJ+lWN9zMysgjyfWawK06JiQulfgTbg2H7mzwPmAUyfPn246mdmZuR7RLAKmFYyPhVYXZ5I0gnAucCciOioVFBEXBwRbRHR1tramktlzcyKKs9AsAiYIekgSU3AKcCC0gSSjgS+SQoCa3Ksi5mZ9SO3QBAR3cB84FpgGXBlRCyVdIGkOVmyLwJjgR9LulPSgn6KMzOznOR5joCIWAgsLJt2fsnwCXku38zMBuc7i83MCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgcg0Ekk6SdL+k5ZLOrjD/GEm3S+qW9MY862JmZpXlFggk1QMXAbOBmcCpkmaWJXsIOA24PK96mJnZwPJ8VOUsYHlErACQdAUwF7i3L0FEPJDN682xHmZmNoA8A8EUYGXJ+CrgqKEUJGkeMC8b3Sjp/iHWaSLw2BDzOr/z7+r8T4c6OP/um/+A/mbkGQhUYVoMpaCIuBi4eOeqA5IWR0Sb8zv/7pj/6VAH59+98/cnz5PFq4BpJeNTgdU5Ls/MzIYgz0CwCJgh6SBJTcApwIIcl2dmZkOQWyCIiG5gPnAtsAy4MiKWSrpA0hwASS+StAr4F+CbkpbmVZ/MzjYvOb/z78r8T4c6OP/unb8iRQyp2d7MzPYQvrPYzKzgHAjMzAquEIFA0iWS1khaMsT80yT9XtIySUslfaDG/C2SbpV0V5b/k0OsR72kOyRdM4S8D0i6R9KdkhYPIf8ESVdJui/7Hl5cQ95Ds+X2vdZL+mCNyz8z++6WSPqhpJYa838gy7u0mmVXWmck7SPpekl/zd73rjH/v2TL75U04CWA/eT/Yvb93y3pakkTasz/qSzvnZKuk7R/LflL5p0lKSRNrHH5n5D0cMl6cHKty5d0ulK3NUslXVjj8n9UsuwHJN1ZY/4jJN3c9x+SNKvG/M+X9Ofsf/gLSeMHyF9xm1PLOliTiNjjX8AxwAuAJUPMvx/wgmx4HPAXYGYN+QWMzYYbgVuAo4dQjw+RuuO4Zgh5HwAm7sR3+D/Au7PhJmDCEMupB/4BHFBDninA34FR2fiVwGk15D8cWAKMJt078xtgRq3rDHAhcHY2fDbwhRrzPxs4FLgBaBvC8k8EGrLhLwxh+eNLhs8AvlFL/mz6NNIFIA8OtD71s/xPAGdV+ZtVyv/y7LdrzsYn1Vr/kvlfBs6vcfnXAbOz4ZOBG2rMvwg4Nht+J/CpAfJX3ObUsg7W8irEEUFE3ASs3Yn8j0TE7dnwBtJVUFNqyB8RsTEbbcxeNZ2llzQVeDXw7VryDYdsz+UY4DsAEdEZEeuGWNzxwN8i4sEa8zUAoyQ1kDbotdyT8mzg5ojYHOlqthuB1w2UoZ91Zi4pIJK9v7aW/BGxLCKquiu+n/zXZfUHuJl0b04t+deXjI5hgHVwgP/MV4CPDpR3kPxV6Sf/+4DPR0RHlmbNUJYvScCbgB/WmD+Avr34vRhgHewn/6HATdnw9cAbBsjf3zan6uNQcQQAAAfRSURBVHWwFoUIBMNJ0oHAkaS9+lry1WeHomuA6yOipvzAV0l/wKH2yxTAdZJuU+qyoxbPBNqB72ZNU9+WNGaI9TiFAf6AlUTEw8CXSJ0UPgI8GRHX1VDEEuAYSftKGk3am5s2SJ5KJkfEI1mdHgEmDaGM4fJO4Fe1ZpL0GUkrgbcC59eYdw7wcETcVetyS8zPmqcuGUKzxiHAyyTdIulGSS8aYh1eBjwaEX+tMd8HgS9m39+XgHNqzL8EmJMN/wtVroNl25xc1kEHghpIGgv8BPhg2d7VoCKiJyKOIO3FzZJ0eA3LfQ2wJiJuq6nC23tpRLyA1Bvs+yUdU0PeBtJh7tcj4khgE+mwtCZKNxbOAX5cY769SXtCBwH7A2Mk/Wu1+SNiGakp5Xrg18BdQPeAmZ7GJJ1Lqv8Pas0bEedGxLQs7/waljkaOJcag0eZrwMHA0eQAvqXa8zfAOwNHA18BLgy27uv1anUuDOSeR9wZvb9nUl2hFyDd5L+e7eRmns6B8uwM9ucWjgQVElSI+kH+UFE/HSo5WRNKjcAJ9WQ7aXAHEkPAFcAr5B0WY3LXZ29rwGuJvUOW61VwKqSo5irSIGhVrOB2yPi0RrznQD8PSLaI6IL+CnwkloKiIjvRMQLIuIY0iF7rXuDAI9K2g8ge++3aSIvkt4OvAZ4a2QNxUN0OQM0TVRwMCkQ35Wth1OB2yU9o9oCIuLRbIeoF/gWta2DkNbDn2ZNrbeSjo77PWFdSda0+HrgRzUuG+DtpHUP0s5MTfWPiPsi4sSIeCEpEP1tkLpW2ubksg46EFQh2+v4DrAsIv5rCPlb+67wkDSKtGG7r9r8EXFOREyNiANJTSu/i4iq94gljZE0rm+YdNKx6iuoIuIfwEpJh2aTjqekO/EaDHVP7CHgaEmjs9/ieFKbadUkTcrep5M2BEOpxwLSxoDs/edDKGPIJJ0EfAyYExGbh5B/RsnoHGpbB++JiEkRcWC2Hq4incz8Rw3L369k9HXUsA5mfga8IivrENJFC7X2xHkCcF9ErKoxH6RzAsdmw6+gxp2JknWwDjgP+MYAafvb5uSzDg7HGeen+4v0p38E6CKtwO+qMf8/kdrY7wbuzF4n15D/ecAdWf4lDHC1QhVlHUeNVw2R2vjvyl5LgXOHsNwjgMXZZ/gZsHeN+UcDjwN7DfFzf5K04VoCfJ/sypEa8v8vKXjdBRw/lHUG2Bf4LWkD8Ftgnxrzvy4b7gAeBa6tMf9yUtfufevgQFf9VMr/k+z7uxv4BTBlqP8ZBrkKrZ/lfx+4J1v+AmC/GvM3AZdln+F24BW11h+4FHjvEH//fwJuy9ahW4AX1pj/A6Srf/4CfJ6sZ4d+8lfc5tSyDtbychcTZmYF56YhM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgsN2epM9JOk7SayWdXTL90qy3y+ZsfGJ2M9Rg5f2pijQPqELvm0o9bJ5V40eomaSv9t0dXqkukpok3ZTdQGU2IAcC2xMcRbqu+1jS/QKleki39lctImq6a3m4SKqvMt0+pN5rb+ovTUR0kq4zf/MwVc/2YA4EtttS6p//buBFwJ+BdwNfl1TaH85XgTMr7RlL+oikRVknaJ8smb4xe6+T9LWsP/hrJC2U9MaSIk6XdHvWv/xhJdOfL+l3WZ/x78nKUlbfJVn6N2fTj1Pqd/5y4J7sLvBfKj27YklfujJvJPWZVP55Rkn6dd8ySTf+vXXQL9IKz4eNttuKiI9I+jHwb6RnNdwQES8tS/YQ8IcszS/6Jko6EZhB6i9GwAJJx5TtZb8eOBB4LqmXx2XAJSXzH4uIF0j6P8BZpEAE6U7yo0ldPd8h6ZfAi0l3Zz+f1D/OIkl9y5oFHB4Rf5f0BmB1RLw6q+deFT76S0n9PZUaS+qH6nsR8b1s2hJSkDQbkI8IbHd3JOn2+8Pov/+jz5J6qyxd30/MXneQuis4jBQYSv0T8OOI6I3Up87vy+b3dQR2Gylg9Pl5RGyJiMeyPLOysn4YqdO1R0nPROjbSN8aEX/Phu8BTpD0BUkvi4gnK3ye/Ujdgpf6OfDdkiBARPQAnX39TJn1x0cEtluSdASp35ippI7HRqfJuhN4cURs6UsbEcuz6W8qLQL4XER8c6DFDFKNjuy9h+3/S+X9tsQgZW0qqetfJL2Q1K/M5yRdFxEXlKXfApQ/qvOPwGxJl8f2/cY0A1sH/hhWdD4isN1SRNwZ6fkOfY/w+x3wqog4ojQIlPgMqfmmz7XAO7P+3pE0pa93yBJ/AN6QnSuYTOrwrxpzlZ5TvW+WZxHpyVRvVnpAUSvpiW+3lmdUeo7w5oi4jPTwk0rdfS8DnlU27XxSp35fKylrX6Cv626zfjkQ2G4r26A+Eal/+8Miot+usSNiKakJqG/8OlKf/H+WdA+pzb28CeUnpJ4jlwDfJF2ZVKmpptytwC9Jj5P8VKRnQVxN6knyLlLQ+mhU7sL5ucCt2RHMucCnK6T5JZWD0geBFj31UPeXAwurqK8VnHsfNRuApLERsTHbu76V9KS3qvvgz7FefwBeEwM8O1rST4FzosrnJFtx+RyB2cCuyR4q1ETau9/lQSDzYWA6UDEQKD0W9GcOAlYNHxGYmRWczxGYmRWcA4GZWcE5EJiZFZwDgZlZwTkQmJkV3P8HxfijyxeDj8QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8iH3FweVGzwI",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "train_x = torch.from_numpy(train_data).float().to(device)\n",
        "test_x = torch.from_numpy(test_data).float().to(device)\n",
        "\n",
        "train_y = torch.tensor(train_y, dtype=torch.long).to(device)\n",
        "test_y = torch.tensor(test_y, dtype=torch.long).to(device)\n",
        "\n",
        "trainset = TensorDataset(train_x, train_y)\n",
        "testset = TensorDataset(test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RaTzaxY4GzwN"
      },
      "source": [
        "# 2. Train Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "indAskSfGzwP"
      },
      "source": [
        "## 2.a. Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sb_RjUgnGzwR",
        "colab": {}
      },
      "source": [
        "def evaluate_preds(y_gt, y_pred):\n",
        "    precision = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    recall = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    positive = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    true_positive = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    f1_scores = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} \n",
        "    classes = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    \n",
        "    true_samples = generate_true_labels(y_gt)\n",
        "    for outer_index in range(0, len(y_pred)):\n",
        "        for inner_index in range(0, len(y_pred[outer_index])):\n",
        "            if y_pred[outer_index][inner_index] == y_gt[outer_index][inner_index]:\n",
        "                true_positive[y_pred[outer_index][inner_index]] += 1\n",
        "            positive[y_pred[outer_index][inner_index]] += 1\n",
        "            classes[y_pred[outer_index][inner_index]] += 1\n",
        "    \n",
        "    for keys, values in classes.items():\n",
        "        if positive[keys] <= 0.0:\n",
        "            precision[keys] = 0.0\n",
        "        else:\n",
        "            precision[keys] = (true_positive[keys]/positive[keys]) * 100\n",
        "        if true_samples[keys] <= 0.0:\n",
        "            recall[keys] = 0.0\n",
        "        else:\n",
        "            recall[keys] = (true_positive[keys]/true_samples[keys]) * 100\n",
        "    \n",
        "    for keys, values in classes.items():\n",
        "        if recall[keys] <= 0.0:\n",
        "            f1_scores[keys] = 0.0\n",
        "        else:\n",
        "            f1_scores[keys] = 2*((precision[keys]*recall[keys])/(precision[keys]+recall[keys]))\n",
        "    return precision, recall, f1_scores\n",
        "    pass\n",
        "\n",
        "\n",
        "def generate_true_labels(y_gt):\n",
        "    true_labels = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "    for labels in y_gt:\n",
        "        for label in labels:\n",
        "            true_labels[label] += 1\n",
        "    return true_labels\n",
        "\n",
        "def visualize_evaluation(classes, precision, recall, f1_scores):\n",
        "    data = {'Labels/Malwares': list(classes.keys()), 'Precision': list(precision.values()), 'Recall': list(recall.values()), 'F1 Score': list(f1_scores.values())}\n",
        "    dataframe = pandas.DataFrame(data=data)\n",
        "    print(dataframe)\n",
        "\n",
        "\n",
        "def save_model(model, out_path):\n",
        "    checkpoint = {'epoch': epoch,'state_dict': model.state_dict(),'optimizer' : optimizer.state_dict(),'loss': loss_function}\n",
        "    torch.save(checkpoint, out_path)\n",
        "    pass\n",
        "\n",
        "\n",
        "def save_data(eval_data, out_path):\n",
        "    with open(out_path, 'wb') as wf:\n",
        "        pickle.dump(eval_data, wf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A9IhSwvwGzwT"
      },
      "source": [
        "## 2.b. Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZwPBb_yGzwW",
        "colab": {}
      },
      "source": [
        "class NetTemplate(nn.Module):\n",
        "    def __init__(self, input_dim, h1, h2, h3, output_dim):\n",
        "        super(NetTemplate, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.fc3 = nn.Linear(h2, h3)\n",
        "        self.fc4 = nn.Linear(h3, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UwA6OwOZGzwZ"
      },
      "source": [
        "## 2.c. Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akmy6QpwGzwa",
        "colab": {}
      },
      "source": [
        "# Define your hyperparameters here\n",
        "torch.manual_seed(42)\n",
        "in_dims = trainset[0][0].shape[0]\n",
        "h1, h2, h3 = 128, 128, 64\n",
        "out_dims = len(class_to_idx)\n",
        "\n",
        "# Optimization\n",
        "n_epochs = 25\n",
        "batch_size = 16\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "log_interval = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-9nplb7Gzwf"
      },
      "source": [
        "## 2.d. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1pZCSJJEGzwg",
        "colab": {}
      },
      "source": [
        "network = NetTemplate(in_dims, h1, h2, h3, out_dims).to(device)\n",
        "\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "train_dataloader = DataLoader(dataset = trainset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset = testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X4UlGimyGzwp",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "targets = []\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(test_dataloader.dataset) for i in range(0,n_epochs)]\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        data, target = data.to(device),target.to(device)\n",
        "        data = data.view(-1, in_dims)\n",
        "        optimizer.zero_grad()\n",
        "        net_out = network(data)\n",
        "        loss = loss_function(net_out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append((batch_idx*64) + ((epoch-1)*len(train_dataloader.dataset)))\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
        "                    100. * batch_idx / len(train_dataloader), loss.item()))\n",
        "            \n",
        "def test():    \n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    \n",
        "    for data, target in test_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data = data.view(-1, in_dims)\n",
        "        net_out = network(data)\n",
        "        test_loss += loss_function(net_out, target).item()\n",
        "        pred = net_out.data.max(1)[1]\n",
        "        predictions.append(pred.data.to('cpu').numpy())\n",
        "        targets.append(target.data.to('cpu').numpy())\n",
        "        test_correct += pred.eq(target.data).sum()\n",
        "\n",
        "    test_loss /= len(test_dataloader.dataset)\n",
        "    test_accuracies.append(100 * (test_correct / len(test_dataloader.dataset)))\n",
        "    test_losses.append(test_loss)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, test_correct, len(test_dataloader.dataset),\n",
        "            100. * test_correct / len(test_dataloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8wT5mN3EQfx",
        "colab_type": "code",
        "colab": {},
        "outputId": "156c9a87-8dcd-44b4-c733-5f6cb0eb8889"
      },
      "source": [
        "for epoch in range(1, n_epochs+1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\agarw\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/1500 (0%)]\tLoss: 2.330157\n",
            "Train Epoch: 1 [160/1500 (11%)]\tLoss: 1.879221\n",
            "Train Epoch: 1 [320/1500 (21%)]\tLoss: 1.630816\n",
            "Train Epoch: 1 [480/1500 (32%)]\tLoss: 0.892115\n",
            "Train Epoch: 1 [640/1500 (43%)]\tLoss: 0.657833\n",
            "Train Epoch: 1 [800/1500 (53%)]\tLoss: 0.859767\n",
            "Train Epoch: 1 [960/1500 (64%)]\tLoss: 1.159757\n",
            "Train Epoch: 1 [1120/1500 (74%)]\tLoss: 0.778367\n",
            "Train Epoch: 1 [1280/1500 (85%)]\tLoss: 1.318811\n",
            "Train Epoch: 1 [1440/1500 (96%)]\tLoss: 0.498624\n",
            "\n",
            "Test set: Average loss: 0.0477, Accuracy: 1153/1500 (77%)\n",
            "\n",
            "Train Epoch: 2 [0/1500 (0%)]\tLoss: 0.508964\n",
            "Train Epoch: 2 [160/1500 (11%)]\tLoss: 1.282460\n",
            "Train Epoch: 2 [320/1500 (21%)]\tLoss: 0.843480\n",
            "Train Epoch: 2 [480/1500 (32%)]\tLoss: 0.844548\n",
            "Train Epoch: 2 [640/1500 (43%)]\tLoss: 0.775091\n",
            "Train Epoch: 2 [800/1500 (53%)]\tLoss: 0.651644\n",
            "Train Epoch: 2 [960/1500 (64%)]\tLoss: 0.582337\n",
            "Train Epoch: 2 [1120/1500 (74%)]\tLoss: 0.941119\n",
            "Train Epoch: 2 [1280/1500 (85%)]\tLoss: 0.442889\n",
            "Train Epoch: 2 [1440/1500 (96%)]\tLoss: 0.783449\n",
            "\n",
            "Test set: Average loss: 0.0448, Accuracy: 1195/1500 (80%)\n",
            "\n",
            "Train Epoch: 3 [0/1500 (0%)]\tLoss: 0.491739\n",
            "Train Epoch: 3 [160/1500 (11%)]\tLoss: 0.949729\n",
            "Train Epoch: 3 [320/1500 (21%)]\tLoss: 0.782327\n",
            "Train Epoch: 3 [480/1500 (32%)]\tLoss: 0.644457\n",
            "Train Epoch: 3 [640/1500 (43%)]\tLoss: 0.764458\n",
            "Train Epoch: 3 [800/1500 (53%)]\tLoss: 0.419163\n",
            "Train Epoch: 3 [960/1500 (64%)]\tLoss: 0.503609\n",
            "Train Epoch: 3 [1120/1500 (74%)]\tLoss: 0.740329\n",
            "Train Epoch: 3 [1280/1500 (85%)]\tLoss: 0.893023\n",
            "Train Epoch: 3 [1440/1500 (96%)]\tLoss: 1.068607\n",
            "\n",
            "Test set: Average loss: 0.0410, Accuracy: 1199/1500 (80%)\n",
            "\n",
            "Train Epoch: 4 [0/1500 (0%)]\tLoss: 0.482487\n",
            "Train Epoch: 4 [160/1500 (11%)]\tLoss: 0.808420\n",
            "Train Epoch: 4 [320/1500 (21%)]\tLoss: 0.252085\n",
            "Train Epoch: 4 [480/1500 (32%)]\tLoss: 0.401690\n",
            "Train Epoch: 4 [640/1500 (43%)]\tLoss: 0.711178\n",
            "Train Epoch: 4 [800/1500 (53%)]\tLoss: 1.101010\n",
            "Train Epoch: 4 [960/1500 (64%)]\tLoss: 0.368486\n",
            "Train Epoch: 4 [1120/1500 (74%)]\tLoss: 1.209934\n",
            "Train Epoch: 4 [1280/1500 (85%)]\tLoss: 0.734725\n",
            "Train Epoch: 4 [1440/1500 (96%)]\tLoss: 0.628231\n",
            "\n",
            "Test set: Average loss: 0.0392, Accuracy: 1190/1500 (79%)\n",
            "\n",
            "Train Epoch: 5 [0/1500 (0%)]\tLoss: 0.353483\n",
            "Train Epoch: 5 [160/1500 (11%)]\tLoss: 0.259804\n",
            "Train Epoch: 5 [320/1500 (21%)]\tLoss: 0.629624\n",
            "Train Epoch: 5 [480/1500 (32%)]\tLoss: 0.953894\n",
            "Train Epoch: 5 [640/1500 (43%)]\tLoss: 0.437332\n",
            "Train Epoch: 5 [800/1500 (53%)]\tLoss: 0.689533\n",
            "Train Epoch: 5 [960/1500 (64%)]\tLoss: 0.678176\n",
            "Train Epoch: 5 [1120/1500 (74%)]\tLoss: 0.805456\n",
            "Train Epoch: 5 [1280/1500 (85%)]\tLoss: 0.576234\n",
            "Train Epoch: 5 [1440/1500 (96%)]\tLoss: 0.508417\n",
            "\n",
            "Test set: Average loss: 0.0510, Accuracy: 1173/1500 (78%)\n",
            "\n",
            "Train Epoch: 6 [0/1500 (0%)]\tLoss: 0.389231\n",
            "Train Epoch: 6 [160/1500 (11%)]\tLoss: 0.340845\n",
            "Train Epoch: 6 [320/1500 (21%)]\tLoss: 0.279449\n",
            "Train Epoch: 6 [480/1500 (32%)]\tLoss: 0.579938\n",
            "Train Epoch: 6 [640/1500 (43%)]\tLoss: 0.326732\n",
            "Train Epoch: 6 [800/1500 (53%)]\tLoss: 1.326120\n",
            "Train Epoch: 6 [960/1500 (64%)]\tLoss: 0.439111\n",
            "Train Epoch: 6 [1120/1500 (74%)]\tLoss: 1.234170\n",
            "Train Epoch: 6 [1280/1500 (85%)]\tLoss: 0.748861\n",
            "Train Epoch: 6 [1440/1500 (96%)]\tLoss: 0.776202\n",
            "\n",
            "Test set: Average loss: 0.0998, Accuracy: 1115/1500 (74%)\n",
            "\n",
            "Train Epoch: 7 [0/1500 (0%)]\tLoss: 1.899961\n",
            "Train Epoch: 7 [160/1500 (11%)]\tLoss: 0.504892\n",
            "Train Epoch: 7 [320/1500 (21%)]\tLoss: 0.684556\n",
            "Train Epoch: 7 [480/1500 (32%)]\tLoss: 0.606090\n",
            "Train Epoch: 7 [640/1500 (43%)]\tLoss: 0.919692\n",
            "Train Epoch: 7 [800/1500 (53%)]\tLoss: 1.094854\n",
            "Train Epoch: 7 [960/1500 (64%)]\tLoss: 0.445117\n",
            "Train Epoch: 7 [1120/1500 (74%)]\tLoss: 0.191716\n",
            "Train Epoch: 7 [1280/1500 (85%)]\tLoss: 0.408360\n",
            "Train Epoch: 7 [1440/1500 (96%)]\tLoss: 0.514673\n",
            "\n",
            "Test set: Average loss: 0.0451, Accuracy: 1155/1500 (77%)\n",
            "\n",
            "Train Epoch: 8 [0/1500 (0%)]\tLoss: 0.317716\n",
            "Train Epoch: 8 [160/1500 (11%)]\tLoss: 0.359338\n",
            "Train Epoch: 8 [320/1500 (21%)]\tLoss: 0.563620\n",
            "Train Epoch: 8 [480/1500 (32%)]\tLoss: 0.568280\n",
            "Train Epoch: 8 [640/1500 (43%)]\tLoss: 0.215105\n",
            "Train Epoch: 8 [800/1500 (53%)]\tLoss: 0.447938\n",
            "Train Epoch: 8 [960/1500 (64%)]\tLoss: 0.673450\n",
            "Train Epoch: 8 [1120/1500 (74%)]\tLoss: 0.898324\n",
            "Train Epoch: 8 [1280/1500 (85%)]\tLoss: 0.252400\n",
            "Train Epoch: 8 [1440/1500 (96%)]\tLoss: 0.630303\n",
            "\n",
            "Test set: Average loss: 0.0438, Accuracy: 1204/1500 (80%)\n",
            "\n",
            "Train Epoch: 9 [0/1500 (0%)]\tLoss: 0.344310\n",
            "Train Epoch: 9 [160/1500 (11%)]\tLoss: 0.590506\n",
            "Train Epoch: 9 [320/1500 (21%)]\tLoss: 0.549596\n",
            "Train Epoch: 9 [480/1500 (32%)]\tLoss: 0.862976\n",
            "Train Epoch: 9 [640/1500 (43%)]\tLoss: 0.420234\n",
            "Train Epoch: 9 [800/1500 (53%)]\tLoss: 0.362692\n",
            "Train Epoch: 9 [960/1500 (64%)]\tLoss: 0.455478\n",
            "Train Epoch: 9 [1120/1500 (74%)]\tLoss: 0.360970\n",
            "Train Epoch: 9 [1280/1500 (85%)]\tLoss: 0.615037\n",
            "Train Epoch: 9 [1440/1500 (96%)]\tLoss: 0.426769\n",
            "\n",
            "Test set: Average loss: 0.0490, Accuracy: 1173/1500 (78%)\n",
            "\n",
            "Train Epoch: 10 [0/1500 (0%)]\tLoss: 0.920348\n",
            "Train Epoch: 10 [160/1500 (11%)]\tLoss: 0.457362\n",
            "Train Epoch: 10 [320/1500 (21%)]\tLoss: 0.804987\n",
            "Train Epoch: 10 [480/1500 (32%)]\tLoss: 0.565275\n",
            "Train Epoch: 10 [640/1500 (43%)]\tLoss: 0.765363\n",
            "Train Epoch: 10 [800/1500 (53%)]\tLoss: 0.655265\n",
            "Train Epoch: 10 [960/1500 (64%)]\tLoss: 0.511872\n",
            "Train Epoch: 10 [1120/1500 (74%)]\tLoss: 0.207560\n",
            "Train Epoch: 10 [1280/1500 (85%)]\tLoss: 0.417884\n",
            "Train Epoch: 10 [1440/1500 (96%)]\tLoss: 0.239279\n",
            "\n",
            "Test set: Average loss: 0.0421, Accuracy: 1189/1500 (79%)\n",
            "\n",
            "Train Epoch: 11 [0/1500 (0%)]\tLoss: 0.449892\n",
            "Train Epoch: 11 [160/1500 (11%)]\tLoss: 0.248825\n",
            "Train Epoch: 11 [320/1500 (21%)]\tLoss: 0.205411\n",
            "Train Epoch: 11 [480/1500 (32%)]\tLoss: 0.208853\n",
            "Train Epoch: 11 [640/1500 (43%)]\tLoss: 0.407840\n",
            "Train Epoch: 11 [800/1500 (53%)]\tLoss: 0.360843\n",
            "Train Epoch: 11 [960/1500 (64%)]\tLoss: 0.413704\n",
            "Train Epoch: 11 [1120/1500 (74%)]\tLoss: 0.702433\n",
            "Train Epoch: 11 [1280/1500 (85%)]\tLoss: 0.252199\n",
            "Train Epoch: 11 [1440/1500 (96%)]\tLoss: 0.542174\n",
            "\n",
            "Test set: Average loss: 0.0437, Accuracy: 1146/1500 (76%)\n",
            "\n",
            "Train Epoch: 12 [0/1500 (0%)]\tLoss: 0.551318\n",
            "Train Epoch: 12 [160/1500 (11%)]\tLoss: 0.738813\n",
            "Train Epoch: 12 [320/1500 (21%)]\tLoss: 0.665295\n",
            "Train Epoch: 12 [480/1500 (32%)]\tLoss: 0.353595\n",
            "Train Epoch: 12 [640/1500 (43%)]\tLoss: 0.888182\n",
            "Train Epoch: 12 [800/1500 (53%)]\tLoss: 0.208949\n",
            "Train Epoch: 12 [960/1500 (64%)]\tLoss: 0.534038\n",
            "Train Epoch: 12 [1120/1500 (74%)]\tLoss: 0.300929\n",
            "Train Epoch: 12 [1280/1500 (85%)]\tLoss: 0.516812\n",
            "Train Epoch: 12 [1440/1500 (96%)]\tLoss: 0.292471\n",
            "\n",
            "Test set: Average loss: 0.0409, Accuracy: 1193/1500 (80%)\n",
            "\n",
            "Train Epoch: 13 [0/1500 (0%)]\tLoss: 0.279901\n",
            "Train Epoch: 13 [160/1500 (11%)]\tLoss: 0.827482\n",
            "Train Epoch: 13 [320/1500 (21%)]\tLoss: 0.535452\n",
            "Train Epoch: 13 [480/1500 (32%)]\tLoss: 0.687634\n",
            "Train Epoch: 13 [640/1500 (43%)]\tLoss: 0.753982\n",
            "Train Epoch: 13 [800/1500 (53%)]\tLoss: 0.419707\n",
            "Train Epoch: 13 [960/1500 (64%)]\tLoss: 0.561402\n",
            "Train Epoch: 13 [1120/1500 (74%)]\tLoss: 0.625055\n",
            "Train Epoch: 13 [1280/1500 (85%)]\tLoss: 0.286158\n",
            "Train Epoch: 13 [1440/1500 (96%)]\tLoss: 0.482838\n",
            "\n",
            "Test set: Average loss: 0.0424, Accuracy: 1204/1500 (80%)\n",
            "\n",
            "Train Epoch: 14 [0/1500 (0%)]\tLoss: 0.485130\n",
            "Train Epoch: 14 [160/1500 (11%)]\tLoss: 0.689717\n",
            "Train Epoch: 14 [320/1500 (21%)]\tLoss: 0.497757\n",
            "Train Epoch: 14 [480/1500 (32%)]\tLoss: 0.354598\n",
            "Train Epoch: 14 [640/1500 (43%)]\tLoss: 0.411506\n",
            "Train Epoch: 14 [800/1500 (53%)]\tLoss: 0.351869\n",
            "Train Epoch: 14 [960/1500 (64%)]\tLoss: 0.718444\n",
            "Train Epoch: 14 [1120/1500 (74%)]\tLoss: 0.852126\n",
            "Train Epoch: 14 [1280/1500 (85%)]\tLoss: 0.479907\n",
            "Train Epoch: 14 [1440/1500 (96%)]\tLoss: 0.598724\n",
            "\n",
            "Test set: Average loss: 0.0408, Accuracy: 1186/1500 (79%)\n",
            "\n",
            "Train Epoch: 15 [0/1500 (0%)]\tLoss: 0.604403\n",
            "Train Epoch: 15 [160/1500 (11%)]\tLoss: 0.492724\n",
            "Train Epoch: 15 [320/1500 (21%)]\tLoss: 0.433738\n",
            "Train Epoch: 15 [480/1500 (32%)]\tLoss: 0.672756\n",
            "Train Epoch: 15 [640/1500 (43%)]\tLoss: 0.415408\n",
            "Train Epoch: 15 [800/1500 (53%)]\tLoss: 0.269946\n",
            "Train Epoch: 15 [960/1500 (64%)]\tLoss: 0.513475\n",
            "Train Epoch: 15 [1120/1500 (74%)]\tLoss: 0.310438\n",
            "Train Epoch: 15 [1280/1500 (85%)]\tLoss: 0.492712\n",
            "Train Epoch: 15 [1440/1500 (96%)]\tLoss: 0.515447\n",
            "\n",
            "Test set: Average loss: 0.0443, Accuracy: 1209/1500 (81%)\n",
            "\n",
            "Train Epoch: 16 [0/1500 (0%)]\tLoss: 0.398844\n",
            "Train Epoch: 16 [160/1500 (11%)]\tLoss: 0.347462\n",
            "Train Epoch: 16 [320/1500 (21%)]\tLoss: 0.398768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 16 [480/1500 (32%)]\tLoss: 0.299997\n",
            "Train Epoch: 16 [640/1500 (43%)]\tLoss: 0.435844\n",
            "Train Epoch: 16 [800/1500 (53%)]\tLoss: 0.589013\n",
            "Train Epoch: 16 [960/1500 (64%)]\tLoss: 0.515767\n",
            "Train Epoch: 16 [1120/1500 (74%)]\tLoss: 0.219826\n",
            "Train Epoch: 16 [1280/1500 (85%)]\tLoss: 0.386603\n",
            "Train Epoch: 16 [1440/1500 (96%)]\tLoss: 0.287103\n",
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 1206/1500 (80%)\n",
            "\n",
            "Train Epoch: 17 [0/1500 (0%)]\tLoss: 0.407480\n",
            "Train Epoch: 17 [160/1500 (11%)]\tLoss: 0.137766\n",
            "Train Epoch: 17 [320/1500 (21%)]\tLoss: 0.298488\n",
            "Train Epoch: 17 [480/1500 (32%)]\tLoss: 0.492871\n",
            "Train Epoch: 17 [640/1500 (43%)]\tLoss: 0.815627\n",
            "Train Epoch: 17 [800/1500 (53%)]\tLoss: 0.588266\n",
            "Train Epoch: 17 [960/1500 (64%)]\tLoss: 0.628583\n",
            "Train Epoch: 17 [1120/1500 (74%)]\tLoss: 1.147198\n",
            "Train Epoch: 17 [1280/1500 (85%)]\tLoss: 0.334962\n",
            "Train Epoch: 17 [1440/1500 (96%)]\tLoss: 0.382574\n",
            "\n",
            "Test set: Average loss: 0.0503, Accuracy: 1194/1500 (80%)\n",
            "\n",
            "Train Epoch: 18 [0/1500 (0%)]\tLoss: 0.765495\n",
            "Train Epoch: 18 [160/1500 (11%)]\tLoss: 0.677036\n",
            "Train Epoch: 18 [320/1500 (21%)]\tLoss: 0.413688\n",
            "Train Epoch: 18 [480/1500 (32%)]\tLoss: 0.266690\n",
            "Train Epoch: 18 [640/1500 (43%)]\tLoss: 0.387306\n",
            "Train Epoch: 18 [800/1500 (53%)]\tLoss: 0.198098\n",
            "Train Epoch: 18 [960/1500 (64%)]\tLoss: 0.300742\n",
            "Train Epoch: 18 [1120/1500 (74%)]\tLoss: 0.149742\n",
            "Train Epoch: 18 [1280/1500 (85%)]\tLoss: 0.545118\n",
            "Train Epoch: 18 [1440/1500 (96%)]\tLoss: 0.786593\n",
            "\n",
            "Test set: Average loss: 0.0458, Accuracy: 1202/1500 (80%)\n",
            "\n",
            "Train Epoch: 19 [0/1500 (0%)]\tLoss: 0.398420\n",
            "Train Epoch: 19 [160/1500 (11%)]\tLoss: 0.449266\n",
            "Train Epoch: 19 [320/1500 (21%)]\tLoss: 0.360854\n",
            "Train Epoch: 19 [480/1500 (32%)]\tLoss: 0.520029\n",
            "Train Epoch: 19 [640/1500 (43%)]\tLoss: 0.235886\n",
            "Train Epoch: 19 [800/1500 (53%)]\tLoss: 0.144303\n",
            "Train Epoch: 19 [960/1500 (64%)]\tLoss: 0.380450\n",
            "Train Epoch: 19 [1120/1500 (74%)]\tLoss: 0.935487\n",
            "Train Epoch: 19 [1280/1500 (85%)]\tLoss: 0.360889\n",
            "Train Epoch: 19 [1440/1500 (96%)]\tLoss: 0.311056\n",
            "\n",
            "Test set: Average loss: 0.0439, Accuracy: 1180/1500 (79%)\n",
            "\n",
            "Train Epoch: 20 [0/1500 (0%)]\tLoss: 0.386471\n",
            "Train Epoch: 20 [160/1500 (11%)]\tLoss: 0.389690\n",
            "Train Epoch: 20 [320/1500 (21%)]\tLoss: 0.349678\n",
            "Train Epoch: 20 [480/1500 (32%)]\tLoss: 0.164605\n",
            "Train Epoch: 20 [640/1500 (43%)]\tLoss: 0.980421\n",
            "Train Epoch: 20 [800/1500 (53%)]\tLoss: 0.790708\n",
            "Train Epoch: 20 [960/1500 (64%)]\tLoss: 0.338210\n",
            "Train Epoch: 20 [1120/1500 (74%)]\tLoss: 0.674382\n",
            "Train Epoch: 20 [1280/1500 (85%)]\tLoss: 0.306254\n",
            "Train Epoch: 20 [1440/1500 (96%)]\tLoss: 0.460379\n",
            "\n",
            "Test set: Average loss: 0.0444, Accuracy: 1207/1500 (80%)\n",
            "\n",
            "Train Epoch: 21 [0/1500 (0%)]\tLoss: 0.319759\n",
            "Train Epoch: 21 [160/1500 (11%)]\tLoss: 0.239535\n",
            "Train Epoch: 21 [320/1500 (21%)]\tLoss: 0.462499\n",
            "Train Epoch: 21 [480/1500 (32%)]\tLoss: 0.237463\n",
            "Train Epoch: 21 [640/1500 (43%)]\tLoss: 0.522922\n",
            "Train Epoch: 21 [800/1500 (53%)]\tLoss: 0.532216\n",
            "Train Epoch: 21 [960/1500 (64%)]\tLoss: 0.440888\n",
            "Train Epoch: 21 [1120/1500 (74%)]\tLoss: 0.873673\n",
            "Train Epoch: 21 [1280/1500 (85%)]\tLoss: 0.553867\n",
            "Train Epoch: 21 [1440/1500 (96%)]\tLoss: 0.175453\n",
            "\n",
            "Test set: Average loss: 0.0475, Accuracy: 1200/1500 (80%)\n",
            "\n",
            "Train Epoch: 22 [0/1500 (0%)]\tLoss: 0.162545\n",
            "Train Epoch: 22 [160/1500 (11%)]\tLoss: 0.434420\n",
            "Train Epoch: 22 [320/1500 (21%)]\tLoss: 0.520752\n",
            "Train Epoch: 22 [480/1500 (32%)]\tLoss: 0.303822\n",
            "Train Epoch: 22 [640/1500 (43%)]\tLoss: 0.369622\n",
            "Train Epoch: 22 [800/1500 (53%)]\tLoss: 0.279595\n",
            "Train Epoch: 22 [960/1500 (64%)]\tLoss: 0.213305\n",
            "Train Epoch: 22 [1120/1500 (74%)]\tLoss: 0.300079\n",
            "Train Epoch: 22 [1280/1500 (85%)]\tLoss: 0.277483\n",
            "Train Epoch: 22 [1440/1500 (96%)]\tLoss: 0.354665\n",
            "\n",
            "Test set: Average loss: 0.0472, Accuracy: 1172/1500 (78%)\n",
            "\n",
            "Train Epoch: 23 [0/1500 (0%)]\tLoss: 0.345037\n",
            "Train Epoch: 23 [160/1500 (11%)]\tLoss: 0.579319\n",
            "Train Epoch: 23 [320/1500 (21%)]\tLoss: 0.363916\n",
            "Train Epoch: 23 [480/1500 (32%)]\tLoss: 0.166955\n",
            "Train Epoch: 23 [640/1500 (43%)]\tLoss: 0.407190\n",
            "Train Epoch: 23 [800/1500 (53%)]\tLoss: 0.556106\n",
            "Train Epoch: 23 [960/1500 (64%)]\tLoss: 0.475300\n",
            "Train Epoch: 23 [1120/1500 (74%)]\tLoss: 0.383764\n",
            "Train Epoch: 23 [1280/1500 (85%)]\tLoss: 0.451295\n",
            "Train Epoch: 23 [1440/1500 (96%)]\tLoss: 0.619340\n",
            "\n",
            "Test set: Average loss: 0.0482, Accuracy: 1144/1500 (76%)\n",
            "\n",
            "Train Epoch: 24 [0/1500 (0%)]\tLoss: 0.236674\n",
            "Train Epoch: 24 [160/1500 (11%)]\tLoss: 0.296211\n",
            "Train Epoch: 24 [320/1500 (21%)]\tLoss: 0.254951\n",
            "Train Epoch: 24 [480/1500 (32%)]\tLoss: 0.198453\n",
            "Train Epoch: 24 [640/1500 (43%)]\tLoss: 0.272833\n",
            "Train Epoch: 24 [800/1500 (53%)]\tLoss: 0.523477\n",
            "Train Epoch: 24 [960/1500 (64%)]\tLoss: 0.240115\n",
            "Train Epoch: 24 [1120/1500 (74%)]\tLoss: 0.744701\n",
            "Train Epoch: 24 [1280/1500 (85%)]\tLoss: 0.200520\n",
            "Train Epoch: 24 [1440/1500 (96%)]\tLoss: 0.270384\n",
            "\n",
            "Test set: Average loss: 0.0492, Accuracy: 1212/1500 (81%)\n",
            "\n",
            "Train Epoch: 25 [0/1500 (0%)]\tLoss: 0.305962\n",
            "Train Epoch: 25 [160/1500 (11%)]\tLoss: 0.317935\n",
            "Train Epoch: 25 [320/1500 (21%)]\tLoss: 0.565566\n",
            "Train Epoch: 25 [480/1500 (32%)]\tLoss: 0.227892\n",
            "Train Epoch: 25 [640/1500 (43%)]\tLoss: 0.265078\n",
            "Train Epoch: 25 [800/1500 (53%)]\tLoss: 0.357796\n",
            "Train Epoch: 25 [960/1500 (64%)]\tLoss: 0.234519\n",
            "Train Epoch: 25 [1120/1500 (74%)]\tLoss: 0.344172\n",
            "Train Epoch: 25 [1280/1500 (85%)]\tLoss: 0.239927\n",
            "Train Epoch: 25 [1440/1500 (96%)]\tLoss: 0.303994\n",
            "\n",
            "Test set: Average loss: 0.0479, Accuracy: 1202/1500 (80%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bzZX0RP3Gzww"
      },
      "source": [
        "## 2.e. Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd93LpxREQf1",
        "colab_type": "code",
        "colab": {},
        "outputId": "67daa607-c18a-4a52-8adb-d1c442477353"
      },
      "source": [
        "plt.plot(train_counter, train_losses, color='blue')\n",
        "plt.plot(test_counter, test_losses, color='red')\n",
        "plt.legend(['Loss Per Epoch - Optimizer (Adam),', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('#Training Data Processed')\n",
        "plt.ylabel('Negative Log Likelihood Loss')\n",
        "plt.show()\n",
        "\n",
        "precision, recall, f1_scores = evaluate_preds(predictions, targets)\n",
        "visualize_evaluation(class_to_idx, precision, recall, f1_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  Labels/Malwares   Precision     Recall   F1 Score\n",
            "0           Agent   18.431373  37.903226  24.802111\n",
            "1         Allaple  100.000000  98.181818  99.082569\n",
            "2          AutoIt   96.000000  98.647918  97.305948\n",
            "3           Basun   98.178404  73.977643  84.377017\n",
            "4    NothingFound   65.098237  73.696818  69.131179\n",
            "5         Patched    0.000000   0.000000   0.000000\n",
            "6         Swizzor   98.266667  94.185304  96.182708\n",
            "7           Texel   91.720000  78.266064  84.460611\n",
            "8              VB   74.293333  83.463152  78.611738\n",
            "9           Virut   80.852459  85.953294  83.324886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VChdiyc5Gzwz"
      },
      "source": [
        "## 2.f. Save Model + Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8R8xV1RpGzw1",
        "colab": {},
        "outputId": "ced3e520-075e-475c-c378-70b9523622f2"
      },
      "source": [
        "# Feel free to edit anything in this block\n",
        "\n",
        "expt_name = 'bigram_vector_mlp_model_adam_binary_optimizer'\n",
        "\n",
        "model_out_path = '{}.checkpoint.pth'.format(expt_name)\n",
        "save_model(network, model_out_path)\n",
        "\n",
        "eval_data = {\n",
        "    'epoch': n_epochs,\n",
        "    'train_loss': train_losses,\n",
        "    'test_loss': test_losses,\n",
        "    'train_acc': [],\n",
        "    'test_acc': test_accuracies\n",
        "}\n",
        "eval_out_path = '{}.eval.pickle'.format(expt_name)\n",
        "save_data(eval_data, eval_out_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\agarw\\.conda\\envs\\cysecml\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type NLLLoss. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "513S-FPAGzw4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE8YhS-XPEd0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smgb4-I1PEEZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgHi9D-sOvJH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pjVjoJrOtRt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QUuhU2DsGzw6"
      },
      "source": [
        "## 3.a. Summary of Results\n",
        "\n",
        "3 Models with different parameters and input representations are listed as follows:\n",
        "\n",
        "Model 8 - Current Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JCI0kpLzGzw7"
      },
      "source": [
        "|        | Input Representation | Model | Optimizer | Validation Metric | Test Metric |\n",
        "|--------|----------------------|-------|-----------|-------------------|-------------|\n",
        "| Model1 | Unigram Tokens       | GNB   |     -     |       44%         |    46%      |\n",
        "| Model2 | Bigram Tokens        | GNB   |     -     |       42%         |    47%      |\n",
        "| Model3 | Unigram, k=(1,20)    | kNN   |     -     |       74%         |    80%      |\n",
        "| Model4 | Bigram, k=(1,20)     | kNN   |     -     |       80%         |    80%      |\n",
        "| Model5 | Unigram Tokens       | MLP   |     SGD   |       77%         |    76%      |\n",
        "| Model6 | Bigram Tokens        | MLP   |     SGD   |       77%         |    76%      |\n",
        "| Model7 | Unigram Tokens       | MLP   |    Adam   |       78%         |    76%      |      \n",
        "| Model8 | Bigram Tokens*       | MLP   |    Adam   |       78%         |    80%      |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elEvL7HtGzw-",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}